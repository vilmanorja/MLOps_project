# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html



#01_raw: Raw data
customers_raw_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/Customers.csv

loans_raw_data:
  type: partitions.PartitionedDataset
  path: data/01_raw/loans/
  dataset:
    type: pandas.CSVDataset
  filename_suffix: ".csv"


loans_hist_raw_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/Loans_Hist_to_20240531.csv

funds_raw_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/Funds_Hist_to_20240531.csv

transactions_raw_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/Transactions_to_20240531.csv


#02_intermediate: Ingested and Validated
customers_validated:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/customers_validated.csv
  load_args:
    encoding: ISO-8859-1  # Optional, if your file needs it
  save_args:
    lineterminator: "\n"

loans_validated:
  type: partitions.PartitionedDataset
  path: data/02_intermediate/loans_validated
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"

loans_hist_validated:
  type: pandas.CSVDataset
  save_args:
      lineterminator: "\n"
  filepath: data/02_intermediate/loans_hist_validated.csv

funds_validated:
  type: pandas.CSVDataset
  save_args:
      lineterminator: "\n"
  filepath: data/02_intermediate/funds_validated.csv

transactions_validated:
  type: pandas.CSVDataset
  save_args:
      lineterminator: "\n"
  filepath: data/02_intermediate/transactions_validated.csv

#02_intermediate: Cleaned data
customers_cleaned:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/customers_cleaned.csv
  load_args:
    encoding: ISO-8859-1
  save_args:
    index: False
    lineterminator: "\n"

loans_cleaned:
  type: partitions.PartitionedDataset
  path: data/02_intermediate/loans_cleaned
  dataset:
    type: pandas.CSVDataset
    save_args:
      index: False
      lineterminator: "\n"
  filename_suffix: ".csv"

loans_hist_cleaned:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/loans_hist_cleaned.csv
  save_args:
    index: False
    lineterminator: "\n"

funds_cleaned:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/funds_cleaned.csv
  save_args:
    index: False
    lineterminator: "\n"

transactions_cleaned:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/transactions_cleaned.csv
  save_args:
    index: False
    lineterminator: "\n"

#03_primary: features data #
transactional_summaries:
  type: partitions.PartitionedDataset
  path: data/03_primary/transactional_summaries/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: .csv


funds_summaries:
  type: partitions.PartitionedDataset
  path: data/03_primary/funds_summaries/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"

prev_loans_summaries:
  type: partitions.PartitionedDataset
  path: data/03_primary/prev_loans_summaries/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"

active_loans_summaries:
  type: partitions.PartitionedDataset
  path: data/03_primary/active_loans_summaries/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"


loans_to_predict:
  type: partitions.PartitionedDataset
  path: data/03_primary/loans_to_predict/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"


customer_demographics_features:
  type: partitions.PartitionedDataset
  path: data/03_primary/demographics/
  dataset:
    type: pandas.CSVDataset
    save_args:
      lineterminator: "\n"
  filename_suffix: ".csv"



#04_feature data
customer_features:
  type: pandas.CSVDataset
  filepath: data/04_feature/customer_features.csv
  save_args:
    lineterminator: "\n"

reporting_tests_raw:
  type: pandas.CSVDataset
  filepath: data/08_reporting/data_tests_raw.csv

reporting_tests:
  type: pandas.CSVDataset
  filepath: data/08_reporting/data_tests.csv


#feature transform
encoder_transform:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/04_feature/encoder.pkl

#05_model_input
X_train:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train.csv
  save_args:
    lineterminator: "\n"

y_train:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_train.csv
  save_args:
    lineterminator: "\n"


X_test:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test.csv
  save_args:
    lineterminator: "\n"

y_test:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test.csv
  save_args:
    lineterminator: "\n"



y_train_preprocessed:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_train_processed.csv
  save_args:
    lineterminator: "\n"


y_test_preprocessed:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test_processed.csv
  save_args:
    lineterminator: "\n"


#X_train and X_test processed data
X_train_preprocessed:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train_processed.csv
  save_args:
    lineterminator: "\n"

X_test_preprocessed:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test_processed.csv
  save_args:
    lineterminator: "\n"

# 06_models
fitted_preprocessor:
  type: pickle.PickleDataset
  filepath: data/06_models/fitted_preprocessor.pkl
#best columns??
best_columns:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/best_cols.pkl



production_model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/champion_model.pkl

champion_model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/champion_model.pkl

production_model_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: json.JSONDataset
    filepath: data/08_reporting/production_model_metrics.json


production_columns:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/production_cols.pkl


output_plot:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/shap_plot.png

features_with_predict:
  type: pandas.CSVDataset
  filepath: data/07_model_output/features_with_predict.csv
  save_args:
    lineterminator: "\n"